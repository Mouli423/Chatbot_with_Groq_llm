### Groq-Powered LLM Chatbot

A lightweight, high-performance chatbot built using Groq’s LLM API and LangChain.
This project demonstrates how to build a simple conversational AI system that delivers extremely fast responses using Groq’s inference engine.

This repository is ideal for beginners and practitioners who want to experiment with LLMs, explore Groq’s speed, or extend the chatbot into a full AI assistant.

#### Features

Uses Groq LLMs for ultra-fast inference

Clean and simple LangChain-based architecture

Supports real-time conversational chat

#### Easy to extend with:

RAG (Retrieval-Augmented Generation)

Memory (ConversationBuffer, Summary Memory, etc.)

Multi-agent logic

Tools and function calling

Minimal codebase — perfect as a starter template

#### Tech Stack

Python

LangChain

Groq API

Streamlit (if UI included)

dotenv for environment variable management
